{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c703d63-9c68-4a0a-97b9-4764cd83d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdelt import gdelt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm # for progress bars\n",
    "import concurrent.futures\n",
    "import os\n",
    "import calendar\n",
    "import time\n",
    "import requests\n",
    "\n",
    "def fetch_day_with_retry(date_obj, gdelt_obj, retries = 3, delay = 10):\n",
    "    \"\"\"\n",
    "    Fetches data for a single day. Retries if there is a timeout.\n",
    "    \n",
    "    Args:\n",
    "        date_obj (datetime): The date for which to query data.\n",
    "        gdelt_obj (gdelt object): The initialised GDELT object.\n",
    "        retries (int): Number of retry attempts.\n",
    "        delay (int): Delay between retries in seconds.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame or None: DataFrame with essential columns if data is returned; otherwise, None.\n",
    "    \"\"\"\n",
    "    date_str = date_obj.strftime('%Y-%m-%d')\n",
    "    attempt = 0\n",
    "    \n",
    "    while attempt <= retries:\n",
    "        try:\n",
    "            results = gdelt_obj.Search(date_str, table='events')\n",
    "            df = pd.DataFrame(results)[['Actor1CountryCode', 'Actor2CountryCode', 'GoldsteinScale']]\n",
    "            return df if not df.empty else None\n",
    "        except requests.exceptions.ReadTimeout:\n",
    "            print(f\"Timeout on {date_str}, retrying ({attempt + 1}/{retries})...\")\n",
    "            attempt += 1\n",
    "            time.sleep(delay)\n",
    "        except Exception as e:\n",
    "            print(f\"Error on {date_str}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    print(f\"Failed to fetch data for {date_str} after {retries} retries.\")\n",
    "    return None\n",
    "\n",
    "def fetch_gdelt_data(version, start_year, end_year, backup_folder = '../../data/raw'):\n",
    "    \"\"\"\n",
    "    Fetches and aggregates GDELT data on a monthly basis for the given year range.\n",
    "    Exports a CSV for each completed year as a backup.\n",
    "    \n",
    "    Args:\n",
    "        version (int): GDELT version (1 or 2).\n",
    "        start_year (int): Starting year.\n",
    "        end_year (int): Ending year.\n",
    "        backup_folder (str): Path to save yearly backups.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Combined yearly data.\n",
    "    \"\"\"\n",
    "    gdelt_obj = gdelt(version = version)\n",
    "    all_years_data = []\n",
    "\n",
    "    # ensure backup folder exists\n",
    "    os.makedirs(backup_folder, exist_ok = True)\n",
    "    \n",
    "    # loop through years with progress bar\n",
    "    for year in tqdm(range(start_year, end_year + 1), desc = f\"Processing years (v{version})\"):\n",
    "        monthly_data = []\n",
    "        start_date = datetime(year, 1, 1)\n",
    "        \n",
    "        # process month by month in the given year\n",
    "        while start_date.year == year:\n",
    "            # determine last day of current month\n",
    "            last_day = calendar.monthrange(year, start_date.month)[1]\n",
    "            end_date = datetime(year, start_date.month, last_day)\n",
    "\n",
    "            # create list of dates for current month\n",
    "            month_dates = [start_date + timedelta(days = i) for i in range((end_date - start_date).days + 1)]\n",
    "            \n",
    "            # use ThreadPoolExecutor to fetch daily data concurrently\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers = 5) as executor:\n",
    "                month_results = list(executor.map(lambda d: fetch_day_with_retry(d, gdelt_obj), month_dates))\n",
    "                # filter out none results (days with no data)\n",
    "                month_results = [r for r in month_results if r is not None]\n",
    "            \n",
    "            if month_results:\n",
    "                month_df = pd.concat(month_results, ignore_index = True)\n",
    "                # drop rows with missing essential fields\n",
    "                month_df = month_df.dropna(subset=['Actor1CountryCode', 'Actor2CountryCode', 'GoldsteinScale'])\n",
    "                \n",
    "                # group by country pairs and aggregate goldstein scores\n",
    "                df_grouped = month_df.groupby(['Actor1CountryCode', 'Actor2CountryCode']).agg(\n",
    "                    total_goldstein=('GoldsteinScale', 'sum'),\n",
    "                    num_events=('GoldsteinScale', 'count')\n",
    "                ).reset_index()\n",
    "                \n",
    "                # remove rows where the actors are from the same country\n",
    "                df_grouped = df_grouped[df_grouped['Actor1CountryCode'] != df_grouped['Actor2CountryCode']]\n",
    "\n",
    "                # add month_start (first day of the month) and source columns\n",
    "                df_grouped['month_start'] = start_date.strftime('%Y-%m-%d')\n",
    "                df_grouped['source'] = f\"v{version}\"\n",
    "                monthly_data.append(df_grouped)\n",
    "            \n",
    "            # move to the next month\n",
    "            start_date = end_date + timedelta(days = 1)\n",
    "\n",
    "        if monthly_data:\n",
    "            year_df = pd.concat(monthly_data, ignore_index = True)\n",
    "            all_years_data.append(year_df)\n",
    "\n",
    "            # save backup for the completed year\n",
    "            backup_filename = f\"{backup_folder}/gdelt_v{version}_{year}_monthly.csv\"\n",
    "            year_df.to_csv(backup_filename, index=False)\n",
    "\n",
    "            # update progress\n",
    "            tqdm.write(f\"Completed year {year} for v{version}.\")\n",
    "    \n",
    "    return pd.concat(all_years_data, ignore_index=True) if all_years_data else pd.DataFrame()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# MAIN SCRIPT: Fetch and combine GDELT v1 and v2 data\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# fetch gdelt v1 data: 1980 to 2015 (v1 is valid until 17 Feb 2015)\n",
    "gdelt_v1_df = fetch_gdelt_data(version = 1, start_year = 1984, end_year = 1985)\n",
    "gdelt_v1_df = gdelt_v1_df[pd.to_datetime(gdelt_v1_df['month_start']) < pd.Timestamp('2015-02-18')]\n",
    "\n",
    "# fetch gdelt v2 data: 2015 to 2024 (v2 is valid from 18 Feb 2015 onward)\n",
    "gdelt_v2_df = fetch_gdelt_data(version = 2, start_year = 2015, end_year = 2024)\n",
    "gdelt_v2_df = gdelt_v2_df[pd.to_datetime(gdelt_v2_df['month_start']) >= pd.Timestamp('2015-02-18')]\n",
    "\n",
    "# combine the datasets\n",
    "combined_df = pd.concat([gdelt_v1_df, gdelt_v2_df], ignore_index = True)\n",
    "combined_df = combined_df.sort_values(by=['month_start', 'Actor1CountryCode', 'Actor2CountryCode'])\n",
    "\n",
    "# save combined data to csv file\n",
    "combined_df.to_csv('../../data/raw/gdelt_monthly.csv', index = False)\n",
    "print(\"Combined GDELT data saved to '../../data/raw/gdelt_monthly.csv'\")\n",
    "print(combined_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
